---
title: R for Data Science (2e)
---

> 해당 교재는 https://r4ds.hadley.nz/ 에서 확인하실 수 있습니다. 이 문서에 존재하는 모든 인용은 @HadleyWickham2023 입니다.

```{r}
library(ggplot2)
library(ggthemes) 
library(tidyverse) 
library(palmerpenguins)
library(nycflights13)
```

## 1. Data visualization

### 1.2 First steps

#### 1.2.1 The penguins data frame

> penguins contains 344 observations collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER2.

> To make the discussion easier, let’s define some terms: A variable is a quantity, quality, or property that you can measure. A value is the state of a variable when you measure it. The value of a variable may change from measurement to measurement. An observation is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We’ll sometimes refer to an observation as a data point. Tabular data is a set of values, each associated with a variable and an observation. Tabular data is tidy if each value is placed in its own “cell”, each variable in its own column, and each observation in its own row.

#### 1.2.2 Ultimate goal

> Our ultimate goal in this chapter is to recreate the following visualization displaying the relationship between flipper lengths and body masses of these penguins, taking into consideration the species of the penguin.


#### 1.2.4 Adding aesthetics and layers

```{r}
ggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) + 
  geom_point(mapping = aes(color = species, shape = species), na.rm = TRUE) +
  geom_smooth(formula = y ~ x, method = "lm", na.rm = TRUE) +
  labs(title = "Body mass and flipper length",
    subtitle = "Dimensions for Adelie, Chinstrap, and Gentoo Penguins",
    x = "Flipper length (mm)", y = "Body mass (g)",
    color = "Species", shape = "Species") +
  scale_color_colorblind()
```

#### Exercises 1.2.5

- 3
```{r}
ggplot(data = penguins, mapping = aes(x = bill_depth_mm, y = bill_length_mm)) +
  geom_point()
```

- 4
```{r}
ggplot(data = penguins, mapping = aes(x = bill_depth_mm, y = species)) +
  geom_point()
```

- 5
```{r}
ggplot(data = penguins, mapping = aes(x = bill_depth_mm, colour = species)) +
  geom_density()
```

- 8
```{r}
penguins %>% 
  ggplot(mapping = aes(x = flipper_length_mm, y = body_mass_g)) + 
  geom_point(aes(colour = bill_depth_mm), na.rm = TRUE) +
  geom_smooth(formula = y ~ x, method = "loess", na.rm = TRUE)
```


### 1.3 ggplot2 calls

> In the future, you’ll also learn about the pipe, |>, which will allow you to create that plot with.

```{r}
penguins %>% 
  ggplot(mapping = aes(x = flipper_length_mm, y = body_mass_g)) + 
  geom_point(mapping = aes(color = species, shape = species), na.rm = TRUE) +
  geom_smooth(formula = y ~ x, method = "lm", na.rm = TRUE) +
  labs(title = "Body mass and flipper length",
       subtitle = "Dimensions for Adelie, Chinstrap, and Gentoo Penguins",
       x = "Flipper length (mm)", y = "Body mass (g)",
       color = "Species", shape = "Species") +
  scale_color_colorblind()
```

### 1.4 Visualizing distributions

> How you visualize the distribution of a variable depends on the type of variable: categorical or numerical.

- 변수의 개수에 따라 변수가 1개인 경우 히스토그램을 사용하고, 2개인 경우 산점도를 사용하는 것이 일반적(@midway2020principles, @kelleher2011ten, @islam2019overview 등도 함께 참고)

#### 1.4.1 A categorical variable

> A variable is categorical if it can only take one of a small set of values. To examine the distribution of a categorical variable, you can use a bar chart. The height of the bars displays how many observations occurred with each x value.

#### 1.4.2 

> A variable is numerical (or quantitative) if it can take on a wide range of numerical values, and it is sensible to add, subtract, or take averages with those values. Numerical variables can be continuous or discrete.

#### Exercises 1.4.3

- 1
```{r}
penguins %>% 
  ggplot(aes(y = species))+
  geom_bar()
```

- 2
```{r}
penguins %>% 
  ggplot(aes(x = species)) +
  geom_bar(fill = "red")
```

- 4
```{r}
diamonds %>% 
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.5)
```

### 1.5 Visualizing relationships

> To visualize a relationship we need to have at least two variables mapped to aesthetics of a plot.

#### 1.5.1 A numerical and a categorical variable

> A boxplot is a type of visual shorthand for measures of position (percentiles) that describe a distribution. It is also useful for identifying potential outliers.

#### 1.5.2 Two categorical variables

> We can use stacked bar plots to visualize the relationship between two categorical variables.

#### 1.5.3 Two numerical variables

> [...] A scatterplot is probably the most commonly used plot for visualizing the relationship between two numerical variables.

#### 1.5.4 Three or more variables

> However adding too many aesthetic mappings to a plot makes it cluttered and difficult to make sense of. Another way, which is particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data.

#### Exercises 1.5.5

- 6
```{r}
penguins %>% 
  ggplot(mapping = aes(x = bill_length_mm, y = bill_depth_mm, 
                       color = species, shape = species)) +
  geom_point(na.rm = TRUE) +
  labs(color = "Species", shape = "Species")
```

- 7
```{r}
penguins %>% ggplot(aes(x = island, fill = species)) +
  geom_bar(position = "fill")
penguins %>% ggplot(aes(x = species, fill = island)) +
  geom_bar(position = "fill")
```

#### Exercises 1.6.1
```{r}
mpg %>% 
  ggplot() +
  geom_point(aes(x = cty, y = hwy))
# ggsave("mpg-plot.pdf")
```

## 2. Workflow - basics

> You now have some experience running R code. We didn’t give you many details, but you’ve obviously figured out the basics, or you would’ve thrown this book away in frustration! Frustration is natural when you start programming in R because it is such a stickler for punctuation, and even one character out of place can cause it to complain. But while you should expect to be a little frustrated, take comfort in that this experience is typical and temporary: it happens to everyone, and the only way to get over it is to keep trying.

### 2.1 Coding basics

> You will make lots of assignments, and `<-` is a pain to type. You can save time with RStudio’s keyboard shortcut: `Alt + -`(the minus sign). Notice that RStudio automatically surrounds `<-` with spaces, which is a good code formatting practice. Code can be miserable to read on a good day, so giveyoureyesabreak and use spaces.

### 2.2 Comments

> For data analysis code, use comments to explain your overall plan of attack and record important insights as you encounter them. There’s no way to re-capture this knowledge from the code itself.

### 2.3 What’s in a name

> We recommend snake_case, where you separate lowercase words with `_`.

## 3. Data transformation

> Visualization is an important tool for generating insight, but it’s rare that you get the data in exactly the right form you need to make the graph you want. Often you’ll need to create some new variables or summaries to answer your questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with.


> flights is a tibble, a special type of data frame used by the tidyverse to avoid some common gotchas. The most important difference between tibbles and data frames is the way tibbles print; they are designed for large datasets, so they only show the first few rows and only the columns that fit on one screen. There are a few options to see everything. If you’re using RStudio, the most convenient is probably View(flights), which opens an interactive, scrollable, and filterable view. Otherwise you can use print(flights, width = Inf) to show all columns, or use glimpse():

```{r}
flights %>% 
  glimpse()
```

### 3.1.3 dplyr basics

> You’re about to learn the primary dplyr verbs (functions), which will allow you to solve the vast majority of your data manipulation challenges. But before we discuss their individual differences, it’s worth stating what they have in common: 1. The first argument is always a data frame., 2. The subsequent arguments typically describe which columns to operate on using the variable names (without quotes)., 3. The output is always a new data frame.

```{r}
flights |>
  filter(dest == "IAH") |> 
  group_by(year, month, day) |> 
  summarize(
    arr_delay = mean(arr_delay, na.rm = TRUE)
  ) 
```

> dplyr’s verbs are organized into four groups based on what they operate on: rows, columns, groups, or tables. In the following sections, you’ll learn the most important verbs for rows, columns, and groups. Then, we’ll return to the join verbs that work on tables in Chapter 19. Let’s dive in!

### 3.2 Rows

> The most important verbs that operate on rows of a dataset are filter(), which changes which rows are present without changing their order, and arrange(), which changes the order of the rows without changing which are present. Both functions only affect the rows, and the columns are left unchanged. We’ll also discuss distinct() which finds rows with unique values. Unlike arrange() and filter() it can also optionally modify the columns.

#### 3.2.1 filter

> filter() allows you to keep rows based on the values of the columns. The first argument is the data frame. The second and subsequent arguments are the conditions that must be true to keep the row.

```{r}
flights |> 
  filter(dep_delay > 120)
```

> There’s a useful shortcut when you’re combining `|` and `==`: `%in%`. It keeps rows where the variable equals one of the values on the right:

```{r}
flights |> 
  filter(month == 1 & day == 1)
flights |> 
  filter(month == 1 | month == 2)
flights |> 
  filter(month %in% c(1, 2))
jan1 <- flights |> 
  filter(month == 1 & day == 1)
```

#### 3.2.3 arrange

> arrange() changes the order of the rows based on the value of the columns. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns. For example, the following code sorts by the departure time, which is spread over four columns. We get the earliest years first, then within a year, the earliest months, etc

```{r}
flights |> 
  arrange(year, month, day, dep_time)
flights |> 
  arrange(desc(dep_delay))
```

#### 3.2.4 distinct

> distinct() finds all the unique rows in a dataset, so technically, it primarily operates on the rows. Most of the time, however, you’ll want the distinct combination of some variables, so you can also optionally supply column names:

```{r}
flights |> 
  distinct()
flights |> 
  distinct(origin, dest)
```

> Alternatively, if you want to the keep other columns when filtering for unique rows, you can use the .keep_all = TRUE option.

```{r}
flights |> 
  distinct(origin, dest, .keep_all = TRUE)
```

> If you want to find the number of occurrences instead, you’re better off swapping distinct() for count(). With the sort = TRUE argument, you can arrange them in descending order of the number of occurrences. You’ll learn more about count in Section 13.3.

```{r}
flights |>
  count(origin, dest, sort = TRUE)
```

#### Exercises 3.2.5

- 1

```{r}
# Had an arrival delay of two or more hours
flights |>
  filter(arr_delay >= 120) |>
  arrange(desc(arr_delay))

# Flew to Houston (IAH or HOU)
flights |>
  filter(dest %in% c("IAH", "HOU"))
  
# Were operated by United, American, or Delta
flights |>
  filter(carrier %in% c("UA", "AA", "DL"))

# Departed in summer (July, August, and September)
flights |>
  filter(month %in% c(7, 8, 9))

# Arrived more than two hours late, but didn’t leave late
flights |> 
  filter(arr_delay >= 120 & dep_delay <= 0) |> view()

# Were delayed by at least an hour, but made up over 30 minutes in flight
flights |> 
  filter(dep_delay >= 60 & dep_delay - arr_delay > 30)
```

- 2

```{r}
flights |> 
  arrange(desc(dep_delay)) |> 
  arrange(sched_dep_time) |>
  relocate(dep_delay, sched_dep_time)
```

- 3

```{r}
flights |> 
  mutate(speed = distance / (air_time / 60)) |>
  arrange(desc(speed)) |>
  relocate(speed)
```

- 4

```{r}
flights |> 
  distinct(year, month, day) |>
  nrow()
```

- 5

```{r}
flights |> 
  arrange(desc(distance)) |>
  relocate(distance)
```

### 3.3 Columns

> There are four important verbs that affect the columns without changing the rows: mutate() creates new columns that are derived from the existing columns, select() changes which columns are present, rename() changes the names of the columns, and relocate() changes the positions of the columns.

#### 3.3.1 mutate

> The job of mutate() is to add new columns that are calculated from the existing columns. In the transform chapters, you’ll learn a large set of functions that you can use to manipulate different types of variables. For now, we’ll stick with basic algebra, which allows us to compute the gain, how much time a delayed flight made up in the air, and the speed in miles per hour:

```{r}
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60
  )
```

> By default, mutate() adds new columns on the right-hand side of your dataset, which makes it difficult to see what’s happening here. We can use the .before argument to instead add the variables to the left-hand side. [...] Alternatively, you can control which variables are kept with the .keep argument. A particularly useful argument is "used" which specifies that we only keep the columns that were involved or created in the mutate() step. [...] we should think carefully about whether we want the result to be assigned back to flights, overwriting the original data frame with many more variables, or to a new object.

```{r}
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .before = 1
  )

flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .after = day
  )

flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    hours = air_time / 60,
    gain_per_hour = gain / hours,
    .keep = "used"
  )
```

#### 3.3.2 select

> It’s not uncommon to get datasets with hundreds or even thousands of variables. In this situation, the first challenge is often just focusing on the variables you’re interested in. select() allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:

```{r}
# Select columns by name:
flights |> 
  select(year, month, day)

# Select all columns between year and day (inclusive):
flights |> 
  select(year:day)
flights |> 
  select(!year:day)

# Select all columns that are characters:
flights |> 
  select(where(is.character))
```

> You can rename variables as you select() them by using =. The new name appears on the left-hand side of the =, and the old variable appears on the right-hand side:

```{r}
flights |> 
  select(tail_num = tailnum)
```

#### 3.3.3 rename

> If you want to keep all the existing variables and just want to rename a few, you can use rename() instead of select(): [...] If you have a bunch of inconsistently named columns and it would be painful to fix them all by hand, check out janitor::clean_names() which provides some useful automated cleaning.

```{r}
flights |> 
  rename(tail_num = tailnum)
```

#### 3.3.4 relocate

> Use relocate() to move variables around. You might want to collect related variables together or move important variables to the front. By default relocate() moves variables to the front:

```{r}
flights |> 
  relocate(time_hour, air_time)
flights |> 
  relocate(year:dep_time, .after = time_hour)
flights |> 
  relocate(starts_with("arr"), .before = dep_time)
```

#### Exercises 3.3.5

- 1

```{r}
flights |> 
  relocate(dep_time, sched_dep_time, dep_delay)
```

- 2

```{r}
flights |> 
  select(dep_time, dep_delay, arr_time, arr_delay)
flights |> 
  select(starts_with("dep"), starts_with("arr"))
flights |>
  select(dep_time:arr_delay, -contains("sched"))
```

- 3

```{r}
flights |> 
  select(dep_time, dep_time)
```

- 4

```{r}
variables <- c("year", "month", "day", "dep_delay", "arr_delay")

flights |> 
  select(any_of(variables))
```

- 5

```{r}
flights |> 
  select(contains("TIME"))
flights |> 
  select(contains("TIME", ignore.case = FALSE))
```

- 6

```{r}
flights |>
  rename(air_time_min = air_time) |>
  relocate(air_time_min)
```

### 3.4 The Pipe

> While both forms have their time and place, the pipe generally produces data analysis code that is easier to write and read.

```{r}
flights |> 
  filter(dest == "IAH") |> 
  mutate(speed = distance / air_time * 60) |> 
  select(year:day, dep_time, carrier, flight, speed) |> 
  arrange(desc(speed))
```

### 3.5 Groups

> So far you’ve learned about functions that work with rows and columns. dplyr gets even more powerful when you add in the ability to work with groups.

#### 3.5.1 group_by

> Use group_by() to divide your dataset into groups meaningful for your analysis

```{r}
flights |> 
  group_by(month)
```

#### 3.5.2 summarize

> You can create any number of summaries in a single call to summarize(). You’ll learn various useful summaries in the upcoming chapters, but one very useful summary is n(), which returns the number of rows in each group:

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay)
  )

flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE)
  )

flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    n = n()
  )
```

#### 3.5.3 `slice_`

> There are five handy functions that allow you to extract specific rows within each group: - `df |> slice_head(n = 1)` takes the first row from each group. - `df |> slice_tail(n = 1)` takes the last row in each group. - `df |> slice_min(x, n = 1)` takes the row with the smallest value of column x. - `df |> slice_max(x, n = 1)` takes the row with the largest value of column x. - `df |> slice_sample(n = 1)` takes one random row.

```{r}
flights |> 
  group_by(dest) |> 
  slice_max(arr_delay, n = 1) |>
  relocate(dest)
```

#### 3.5.4 Grouping by multiple variables

> You can create groups using more than one variable. For example, we could make a group for each date.

```{r}
daily <- flights |>  
  group_by(year, month, day)
```

> When you summarize a tibble grouped by more than one variable, each summary peels off the last group. In hindsight, this wasn’t a great way to make this function work, but it’s difficult to change without breaking existing code.

```{r}
daily_flights <- daily |> 
  summarize(n = n())

daily_flights <- daily |> 
  summarize(
    n = n(), 
    .groups = "drop_last"
  )
```

#### 3.5.5 Ungrouping

> You might also want to remove grouping from a data frame without using summarize(). You can do this with ungroup(). [...] You get a single row back because dplyr treats all the rows in an ungrouped data frame as belonging to one group.

```{r}
daily |> 
  ungroup()
daily |> 
  ungroup() |>
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    flights = n()
  )
```


#### 3.5.6 .by

> [...] syntax for per-operation grouping, the .by argument. group_by() and ungroup() aren’t going away, but you can now also use the .by argument to group within a single operation. .by works with all verbs and has the advantage that you don’t need to use the .groups argument to suppress the grouping message or ungroup() when you’re done.

```{r}
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = month
  )

flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = c(origin, dest)
  )
```

#### Exercises 3.5.7

- 1

```{r}
flights |>
  group_by(carrier) |>
  summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) |>
  arrange(desc(avg_dep_delay))
```

- 2

```{r}
flights |> 
  group_by(dest) |> 
  arrange(dest, desc(dep_delay)) |>
  slice_head(n = 5) |>
  relocate(dest, dep_delay)
```

- 3

```{r}
flights |>
  group_by(hour) |>
  summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) |>
  ggplot(aes(x = hour, y = avg_dep_delay)) + 
  geom_smooth()
```

- 4

```{r}
flights |> 
  slice_min(dep_delay, n = -5) |>
  relocate(dep_delay)

flights |> 
  slice_min(dep_delay, n = 5) |>
  relocate(dep_delay)

flights |> 
  slice_max(dep_delay, n = -5) |>
  relocate(dep_delay)

flights |> 
  slice_max(dep_delay, n = 5) |>
  relocate(dep_delay)
```

- 6

```{r}
df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)
df |>
  group_by(y)
df |>
  arrange(y)
df |>
  group_by(y) |>
  summarize(mean_x = mean(x))
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))
df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))
```

## 4. Workflow - code style

> [...] Open the palette by pressing Cmd/Ctrl + Shift + P, then type “styler” to see all the shortcuts offered by styler.

### 4.1 Naems

> [...] by mutate()) should use only lowercase letters, numbers, and _. Use _ to separate words within a name. [...] If you have a bunch of names for related things, do your best to be consistent. It’s easy for inconsistencies to arise when you forget a previous convention, so don’t feel bad if you have to go back and rename things. In general, if you have a bunch of variables that are a variation on a theme, you’re better off giving them a common prefix rather than a common suffix because autocomplete works best on the start of a variable.

```{r}
# Strive for:
short_flights <- flights |> filter(air_time < 60)

# Avoid:
SHORTFLIGHTS <- flights |> filter(air_time < 60)
```

### 4.2 Spaces

> Put spaces on either side of mathematical operators apart from ^ (i.e. +, -, ==, <, …), and around the assignment operator (<-).

```{r}
#| eval: false

# Strive for
z <- (a + b)^2 / d

# Avoid
z<-( a + b ) ^ 2/d
```

> It’s OK to add extra spaces if it improves alignment. For example, if you’re creating multiple variables in mutate(), you might want to add spaces so that all the = line up.1 This makes it easier to skim the code.

```{r}
#| eval: false

# Strive for
mean(x, na.rm = TRUE)

# Avoid
mean (x ,na.rm=TRUE)
```

### 4.3 Pipes

> `|>` should always have a space before it and should typically be the last thing on a line. [...] After the first step of the pipeline, indent each line by two spaces. RStudio will automatically put the spaces in for you after a line break following a |> . If you’re putting each argument on its own line, indent by an extra two spaces. Make sure ) is on its own line, and un-indented to match the horizontal position of the function name. [...] Finally, be wary of writing very long pipes, say longer than 10-15 lines. Try to break them up into smaller sub-tasks, giving each task an informative name. The names will help cue the reader into what’s happening and makes it easier to check that intermediate results are as expected. Whenever you can give something an informative name, you should give it an informative name, for example when you fundamentally change the structure of the data, e.g., after pivoting or summarizing. Don’t expect to get it right the first time! This means breaking up long pipelines if there are intermediate states that can get good names.

```{r}
# Strive for 
flights |>  
  filter(!is.na(arr_delay), !is.na(tailnum)) |> 
  count(dest)

# Avoid
flights|>filter(!is.na(arr_delay), !is.na(tailnum))|>count(dest)

# Strive for
flights |>  
  group_by(tailnum) |> 
  summarize(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

# Avoid
flights |>
  group_by(
    tailnum
  ) |> 
  summarize(delay = mean(arr_delay, na.rm = TRUE), n = n())

# Strive for 
flights |>  
  group_by(tailnum) |> 
  summarize(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

# Avoid
flights|>
  group_by(tailnum) |> 
  summarize(
             delay = mean(arr_delay, na.rm = TRUE), 
             n = n()
           )

# Avoid
flights|>
  group_by(tailnum) |> 
  summarize(
  delay = mean(arr_delay, na.rm = TRUE), 
  n = n()
  )

# This fits compactly on one line
df |> mutate(y = x + 1)

# While this takes up 4x as many lines, it's easily extended to 
# more variables and more steps in the future
df |> 
  mutate(
    y = x + 1
  )
```

### 4.4 ggplot2

> The same basic rules that apply to the pipe also apply to ggplot2; just treat `+` the same way as `|>`. [...] Again, if you can’t fit all of the arguments to a function on to a single line, put each argument on its own line:

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    delay = mean(arr_delay, na.rm = TRUE)
  ) |> 
  ggplot(aes(x = month, y = delay)) +
  geom_point() + 
  geom_line()

flights |> 
  group_by(dest) |> 
  summarize(
    distance = mean(distance),
    speed = mean(distance / air_time, na.rm = TRUE)
  ) |> 
  ggplot(aes(x = distance, y = speed)) +
  geom_smooth(
    method = "loess",
    span = 0.5,
    se = FALSE, 
    color = "white", 
    linewidth = 4
  ) +
  geom_point()
```

### Section

> As your scripts get longer, you can use sectioning comments to break up your file into manageable pieces:

```{r}
# Load data --------------------------------------

# Plot data --------------------------------------
```

### Exercises 4.6

```{r}
flights |>
  filter(dest == "IAH") |>
  group_by(year, month, day) |>
  summarize(
    n = n(),
    delay = mean(arr_delay, na.rm = TRUE)
  ) |>
  filter(n > 10)

flights |>
  filter(
    carrier == "UA", 
    dest %in% c("IAH", "HOU"), 
    sched_dep_time > 0900, 
    sched_arr_time < 2000
  ) |>
  group_by(flight) |>
  summarize(
    delay = mean(arr_delay, na.rm = TRUE), 
    cancelled = sum(is.na(arr_delay)), n = n()
  ) |>
  filter(n > 10)
```

## 5. Data tidying

### Tidy data

> “Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy,
> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” — Hadley Wickham

```{r}
library(tidyverse)
library(ggthemes)
```

> One of them, table1, will be much easier to work with inside the tidyverse because it’s tidy.

```{r}
table1 # tidy!
table2
table3
```

> There are three interrelated rules that make a dataset tidy: - Each variable is a column; each column is a variable., - Each observation is a row; each row is an observation., - Each value is a cell; each cell is a single value.

> Why ensure that your data is tidy? There are two main advantages: - If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity., - There’s a specific advantage to placing variables in columns because it allows R’s vectorized nature to shine.

```{r}
# Compute rate per 10,000
table1 |>
  mutate(rate = cases / population * 10000)

table1 |> 
  group_by(year) |> 
  summarize(total_cases = sum(cases))

ggplot(table1, aes(x = year, y = cases)) +
  geom_line(aes(group = country), color = "grey50") +
  geom_point(aes(color = country, shape = country)) +
  scale_x_continuous(breaks = c(1999, 2000)) # x-axis breaks at 1999 and 2000
```

### 연습문제 5.2.1

#### 2

```{r}
table2 |>
  pivot_wider(
    names_from = type,
    values_from = count
  ) |> 
  mutate(rate = cases / population * 10000)
```

```{r}
table3 |>
  separate_wider_delim(
    cols = rate, 
    delim = "/", 
    names = c("cases", "population"),
  ) |>
  mutate(
    cases = as.numeric(cases),
    population = as.numeric(population),
    rate = cases / population * 10000
  )
```

### Lengthening data

The principles of tidy data might seem so obvious that you wonder if you’ll ever encounter a dataset that isn’t tidy. Unfortunately, however, most real data is untidy. There are two main reasons:
- Data is often organized to facilitate some goal other than analysis. For example, it’s common for data to be structured to make data entry, not analysis, easy.
- Most people aren’t familiar with the principles of tidy data, and it’s hard to derive them yourself unless you spend a lot of time working with data.

This means that most real analyses will require at least a little tidying. You’ll begin by figuring out what the underlying variables and observations are. Sometimes this is easy; other times you’ll need to consult with the people who originally generated the data. Next, you’ll pivot your data into a tidy form, with variables in the columns and observations in the rows.

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )

billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )

billboard_longer <- billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  ) |> 
  mutate(
    week = parse_number(week)
  )

billboard_longer |> 
  ggplot(aes(x = week, y = rank, group = track)) + 
  geom_line(alpha = 0.25) + 
  scale_y_reverse()
```

### How does pivoting work?

```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)

df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
```


### Many variables in column names

> [...] To organize these six pieces of information in six separate columns, we use pivot_longer() with a vector of column names for names_to and instructors for splitting the original variable names into pieces for names_sep as well as a column name for values_to

```{r}
who2 |> 
  pivot_longer(
    cols = !(country:year),
    names_to = c("diagnosis", "gender", "age"), 
    names_sep = "_",
    values_to = "count"
  )
```

### Data and variable names in the column headers

> To solve this problem we again need to supply a vector to names_to but this time we use the special ".value" sentinel; this isn’t the name of a variable but a unique value that tells pivot_longer() to do something different. This overrides the usual values_to argument to use the first component of the pivoted column name as a variable name in the output.

```{r}
household |> 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

### Widening data

```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)

df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )

df |> 
  distinct(measurement) |> 
  pull()

df |> 
  select(-measurement, -value) |> 
  distinct()

df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
```

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "A",        "bp1",    102,
  "A",        "bp2",    120,
  "B",        "bp1",    140, 
  "B",        "bp2",    115
)

df |>
  pivot_wider(
    names_from = measurement,
    values_from = value
  )

df |> 
  group_by(id, measurement) |> 
  summarize(n = n(), .groups = "drop") |> 
  filter(n > 1)
```

## Workflow - scripts and projects

> scripts and projects give you a solid workflow that will serve you well in the future: - Create one RStudio project for each data analysis project., - Save your scripts (with informative names) in the project, edit them, run them in bits or as a whole., - Restart R frequently to make sure you’ve captured everything in your scripts., - Only ever use relative paths, not absolute paths., - Then everything you need is in one place and cleanly separated from all the other projects that you are working on.

## Reading data from a file

```{r}
students <- read_csv("data/students.csv")
students <- read_csv("data/students.csv", na = c("N/A", ""))
```

```{r}
students |> 
  rename(
    student_id = `Student ID`,
    full_name = `Full Name`
  )
```

```{r}
students |> janitor::clean_names()
```

```{r}
students |>
  janitor::clean_names() |>
  mutate(meal_plan = factor(meal_plan))
```

```{r}
students <- students |>
  janitor::clean_names() |>
  mutate(
    meal_plan = factor(meal_plan),
    age = parse_number(if_else(age == "five", "5", age))
  )
```

### 연습문제 7.2.4

```{r}
annoying <- tibble(
  `1` = 1:10,
  `2` = `1` * 2 + rnorm(length(`1`))
)

annoying |>
  select(`1`)

ggplot(annoying, aes(x = `2`, y = `1`)) +
  geom_point()

annoying |>
  mutate(`3` = `2` / `1`)

annoying |>
  mutate(`3` = `2` / `1`) |>
  rename(
    "one" = `1`,
    "two" = `2`,
    "three" = `3`
  )
```

### Data entry

```{r}
tribble(
  ~x, ~y, ~z,
  1, "h", 0.08,
  2, "m", 0.83,
  5, "g", 0.60
)
```

## Workflow - getting help

### Google is your friend

> 막막하다면 Google부터 시작하세요. 일반적으로 검색어에 "R", "tidyverse" 또는 "ggplot2"와 같은 추가적인 정보를 검색어에 포함하세요. Google은 오류 메시지에 특히 유용합니다. 오류 메시지가 표시되었는데 무슨 뜻인지 모르겠다면 Google에서 검색해 보세요! 만약, 오류 메시지가 영어로 되어 있지 않은 경우 `Sys.setenv(LANGUAGE = "en")`를 실행하고 코드를 다시 실행하면 오류가 영어로 출력됩니다. 구글과 함께  [Stack Overflow](https://stackoverflow.com)도 함께 참고하세요.

### Making a reprex
 
인터넷 검색에서 유용한 정보를 찾지 못했다면 재현 가능한 최소한의 예제를 뜻하는 reprex를 준비하는 것이 좋습니다. 좋은 reprex를 만들면 다른 사람들이 더 쉽게 도움을 줄 수 있고, 만드는 과정에서 스스로 문제를 파악할 수 있는 경우가 많습니다. 레프렉스를 만드는 데는 두 가지 부분이 있습니다.

- 첫째, 코드를 재현 가능하게 만들어야 합니다. 즉, 모든 library() 호출을 포함하고 필요한 모든 객체를 생성하는 등 모든 것을 캡처해야 합니다. 이를 확인하는 가장 쉬운 방법은 reprex 패키지를 사용하는 것입니다.

- 둘째, 최소한으로 만들어야 합니다. 문제와 직접 관련이 없는 모든 것을 제거하세요. 여기에는 일반적으로 실생활에서 직면하는 문제보다 훨씬 작고 단순한 R 개체를 만들거나 내장된 데이터를 사용하는 것이 포함됩니다.

많은 작업처럼 들립니다! 그럴 수도 있지만 그만한 보상이 있습니다.

- 80%의 경우, 훌륭한 레프렉스를 만들면 문제의 원인을 파악할 수 있습니다. 독립적이고 최소한의 예시를 작성하는 과정에서 스스로 질문에 답할 수 있는 경우가 얼마나 많은지 놀라울 정도입니다.

- 나머지 20%의 시간에는 다른 사람들이 쉽게 사용할 수 있는 방식으로 문제의 본질을 파악하게 됩니다. 이렇게 하면 도움을 받을 가능성이 크게 높아집니다!

수작업으로 reprex를 만들 때는 실수로 무언가를 놓치기 쉬우므로 다른 사람의 컴퓨터에서 코드를 실행할 수 없게 됩니다. tidyverse의 일부로 설치되는 reprex 패키지를 사용하면 이 문제를 방지할 수 있습니다. 

```{r}
y <- 1:4
mean(y)
```

그런 다음 기본 출력 형식이 GitHub용으로 지정된 reprex()를 호출합니다.

```{r}
reprex::reprex(y)
```

멋지게 렌더링된 HTML 미리 보기가 RStudio의 뷰어(RStudio를 사용하는 경우) 또는 기본 브라우저에 표시됩니다. 클립보드에 자동으로 복사됩니다. 이 텍스트는 마크다운이라는 방식으로 작성되며, 마크다운을 StackOverflow나 Github 같은 사이트에 붙여넣으면 코드처럼 보이도록 자동으로 렌더링됩니다. 

누구나 바로 복사하여 붙여넣고 실행할 수 있습니다. 예제를 재현 가능하게 만들려면 필수 패키지, 데이터, 코드 세 가지를 포함해야 합니다.

1. 예제에 필요한 패키지를 쉽게 확인할 수 있도록 스크립트의 맨 위에 패키지가 로드되어야 합니다. 패키지를 설치하거나 마지막으로 업데이트한 이후 수정된 버그를 발견했을 수 있으므로 각 패키지의 최신 버전을 사용하고 있는지 확인하기에 좋은 시기입니다. tidyverse에 있는 패키지의 경우 가장 쉽게 확인할 수 있는 방법은 tidyverse_update()를 실행하는 것입니다.

2. 데이터를 포함하는 가장 쉬운 방법은 `dput()`을 사용하여 데이터를 다시 생성하는 데 필요한 R 코드를 생성하는 것입니다. 예를 들어, R에서 mtcars 데이터 집합을 다시 만들려면 다음 단계를 수행합니다.

- R에서 `dput(mtcars)`를 실행합니다.
- 출력 복사
- reprex에서 mtcars <-를 입력한 다음 붙여넣습니다.

```{r}
dput(mtcars)
reprex::reprex(mtcars)
```

3. 다른 사람들이 코드를 쉽게 읽을 수 있도록 약간의 시간을 투자하세요.

- 변수 등을 올바로 사용했는지 확인하세요.
- 주석을 사용해서 문제가 발생한 부분에 적절한 정보를 추가하세요.
- 문제와 관련이 없는 모든 것은 제거하세요.

새로운 세션을 시작하고, 작성된 스크립트가 재현 가능한 예제인지 확인하세요. 만약, 재현 가능하지 않다면 유사한 예제를 만들 수 있도록 연습해야 합니다. 코드가 포함된 질문을 하는 법을 배우고, 재현 가능하도록 R과 관려된 기술에 시간을 투자하세요.

이 장에서는 그래픽의 레이어 문법(grammar of graphics)을 학습합니다. ggplot2에서 제공하는 가장 중요하고 일반적으로 사용되는 기능을 연습하고 ggplot2를 확장하는 패키지를 소개합니다.

```{r}
library(tidyverse)
```

## Aesthetic mappings

```{r}
# Light
ggplot(mpg, aes(x = displ, y = hwy, color = class)) + geom_point()

# Right
ggplot(mpg, aes(x = displ, y = hwy, shape = class)) + geom_point()
```

클래스(class)가 shape에 매핑되면 두 가지 경고가 표시됩니다:
- 도형 팔레트는 최대 6개의 불연속형 값을 처리할 수 있습니다. 6개를 초과하면 구분이 어려워집니다. 도형이 꼭 필요한 경우 수동으로 도형을 지정하는 것이 좋습니다.
- 누락된 값이 포함된 62개 행을 제거했습니다(geom_point()). 데이터 집합에 62개의 SUV가 있지만 플롯되지 않은 것과 관련이 있습니다.

마찬가지로 클래스를 크기에 매핑하여 각각 포인트의 크기와 alpha 값에 매핑하여 투명도를 제어할 수 있습니다.

```{r}
# Left
ggplot(mpg, aes(x = displ, y = hwy, size = class)) +
  geom_point()

# Right
ggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +
  geom_point()
```

```{r}
students <- read_csv("data/students.csv")
students |> janitor::clean_names()
```

```{r}
students |>
  janitor::clean_names() |>
  mutate(meal_plan = factor(meal_plan))
```

```{r}
students <- students |>
  janitor::clean_names() |>
  mutate(
    meal_plan = factor(meal_plan),
    age = parse_number(if_else(age == "five", "5", age))
  )
```

### 연습문제 7.2.4

```{r}
annoying <- tibble(
  `1` = 1:10,
  `2` = `1` * 2 + rnorm(length(`1`))
)

annoying |>
  select(`1`)

ggplot(annoying, aes(x = `2`, y = `1`)) +
  geom_point()

annoying |>
  mutate(`3` = `2` / `1`)

annoying |>
  mutate(`3` = `2` / `1`) |>
  rename(
    "one" = `1`,
    "two" = `2`,
    "three" = `3`
  )
```

### Data entry

```{r}
tribble(
  ~x, ~y, ~z,
  1, "h", 0.08,
  2, "m", 0.83,
  5, "g", 0.60
)
```

## Layers

이 장에서는 시각화 및 변환을 사용하여 체계적인 방식으로 데이터를 탐색하는 방법, 즉 통계학자들이 탐색적 데이터 분석 또는 줄여서 EDA라고 부르는 작업에 대해서 소개합니다.

1. 데이터에 대한 질문을 생성하세요.
2. 데이터를 시각화, 변환 및 모델링하여 답을 찾아보세요.
3. 학습한 내용을 사용하여 질문을 구체화하거나 새로운 질문을 생성합니다.

EDA는 엄격한 규칙이 있는 알고리즘이나 방법론이 아닙니다. EDA는 정신 혹은 과정의 상태입니다. EDA의 초기 단계에서는 떠오르는 모든 아이디어를 자유롭게 확인해야 합니다. 이러한 아이디어 중 일부는 실현될 수도 있고 일부는 막다른 골목에 부딪힐 수도 있습니다. 탐색을 계속하다 보면 몇 가지 가능성을 발견하게 되고, 집중하게 될 것이고, 결국에는 이를 문서로 작성하여 다른 사람들에게 전달할 수 있을 것입니다.

> EDA is a state of mind.

EDA는 모든 데이터 분석에서 중요한 부분입니다. 질문이 주어지더라도 항상 데이터의 품질을 확인해야 합니다. 데이터 정리는 데이터가 기대에 부합하는지 여부에 대한 EDA의 한 가지 응용 분야일 뿐입니다. 데이터 정리를 수행하려면 시각화, 변환, 모델링 등 EDA의 모든 방법을 활용해야 합니다.

질문을 하고, 데이터로 답변하고, 새로운 질문을 하기 위해 dplyr 및 ggplot2에 대해 배운 내용을 함께 사용해보도록 하겠습니다.

```{r}
library(tidyverse)
```

### Questions

> “There are no routine statistical questions, only questionable statistical routines.” — Sir David Cox

> “Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” — John Tukey

EDA의 목표는 데이터에 대한 이해를 높이는 것입니다. 이를 위한 가장 쉬운 방법은 데이터를 찾아가는 도구로 질문을 사용하는 것입니다. 질문을 하면 데이터 집합의 특정 부분에 주의를 집중시키고 어떤 그래프, 모델 또는 변환을 만들지 결정하는 데 도움이 됩니다.

EDA는 근본적으로 창의적인 프로세스입니다. 대부분의 창의적인 프로세스와 마찬가지로 양질의 질문을 하기 위한 핵심은 많은 양의 질문을 생성하는 것입니다. 분석을 시작할 때 데이터 집합에서 어떤 인사이트를 얻을 수 있는지 모르기 때문에, 분석의 시작 단계에서 드러나는 질문을 하기는 어렵습니다. 반면에, 새로운 질문을 할 때마다 데이터의 새로운 측면에 노출되어 발견할 가능성이 높아집니다. 발견한 내용에 따라 새로운 질문으로 후속 질문을 하면 데이터에서 가장 흥미로운 부분을 빠르게 드릴다운하고 생각을 자극하는 일련의 질문을 개발할 수 있습니다.

연구를 안내하기 위해 어떤 질문을 해야 하는지에 대한 규칙은 없습니다. 하지만 두 가지 유형의 질문은 데이터 내에서 발견을 이끌어내는 데 항상 유용합니다. 이러한 질문은 다음과 같이 느슨하게 표현할 수 있습니다.

- 내 변수 내에서 어떤 유형의 변이가 발생하나요?
- 내 변수 간에 어떤 유형의 공변량이 발생하나요?

이 장의 나머지 부분에서는 이 두 가지 질문에 대해 살펴봅니다. 변이와 공변량이 무엇인지 설명하고 각 질문에 답하는 몇 가지 방법을 보여 드리겠습니다.

### Variation

분포(Variation)란 측정할 때마다 변수의 값이 변하는 경향을 말합니다. 실생활에서 분포를 쉽게 볼 수 있는데, 연속적인 변수를 두 번 측정하면 두 가지 다른 결과를 얻을 수 있습니다. 이는 빛의 속도와 같이 일정한 양을 측정하는 경우에도 마찬가지입니다. 각 측정에는 측정마다 달라지는 소량의 오차가 포함됩니다. 다른 대상(예: 여러 사람의 눈 색깔)이나 다른 시간(예: 다른 순간의 전자의 에너지 준위)에 걸쳐 측정하는 경우에도 변수가 달라질 수 있습니다. 모든 변수에는 고유한 변화 패턴이 있으며, 이를 통해 동일한 관측에 대한 측정 간은 물론 여러 관측에 걸쳐 어떻게 변화하는지에 대한 흥미로운 정보를 얻을 수 있습니다. 이러한 패턴을 이해하는 가장 좋은 방법은 1장에서 배운 변수 값의 분포를 시각화하는 것입니다.

다이아몬드 데이터 집합에서 약 54,000개의 다이아몬드 무게(캐럿) 분포를 시각화하여 탐색을 시작하겠습니다. 캐럿은 숫자 변수이므로 히스토그램을 사용할 수 있습니다.

```{r}
ggplot(diamonds, aes(x = carat)) + 
  geom_histogram(binwidth = 0.5)
```

이제 분포를 시각화할 수 있게 되었으니 그래프에서 무엇을 찾아야 할까요? 어떤 유형의 후속 질문을 해야 할까요? 그래프에서 찾을 수 있는 가장 유용한 정보 유형과 각 정보 유형에 대한 몇 가지 후속 질문 목록을 아래에 정리해 두었습니다. 좋은 후속 질문의 핵심은 호기심(무엇을 더 알고 싶으신가요?)과 회의론(어떻게 오해의 소지가 있을 수 있나요?)에 의존하는 것입니다.


#### Typical values

막대 차트와 히스토그램 모두에서 긴 막대는 변수의 일반적인 값을 나타내고, 짧은 막대는 덜 일반적인 값을 나타냅니다. 막대가 없는 부분은 데이터에서 볼 수 없었던 값을 나타냅니다. 이 정보를 유용한 질문으로 전환하려면 예상치 못한 것이 있는지 찾아보세요.

- 가장 일반적인 값은 무엇인가요? 왜 그럴까요?
- 가장 드문 값은 무엇인가요? 왜 그런가요? 기대치와 일치하나요?
- 특이한 패턴이 보이나요? 이를 설명할 수 있는 것은 무엇인가요?

작은 다이아몬드의 캐럿 분포를 살펴보겠습니다.

```{r}
smaller <- diamonds |> filter(carat < 3)
ggplot(smaller, aes(x = carat)) + geom_histogram(binwidth = 0.01)
```

이 히스토그램은 몇 가지 흥미로운 질문을 제시합니다.

- 전체 캐럿과 일반적인 분수 캐럿의 다이아몬드가 더 많은 이유는 무엇인가요?
- 각 봉우리의 왼쪽보다 오른쪽에 약간 더 많은 다이아몬드가 있는 이유는 무엇인가요?

비주얼리제이션을 통해 데이터에 하위 그룹이 존재함을 시사하는 클러스터를 확인할 수도 있습니다. 하위 그룹을 이해하려면 물어보세요.

- 각 하위 그룹 내의 관측값은 서로 어떻게 유사합니까?
- 개별 클러스터의 관측값은 서로 어떻게 다른가요?
- 클러스터를 어떻게 설명하거나 설명할 수 있나요?
- 클러스터의 모양이 오해의 소지가 있는 이유는 무엇인가요?

이러한 질문 중 일부는 데이터로 답할 수 있지만 일부는 데이터에 대한 도메인 전문 지식이 필요합니다. 예를 들어, 한 변수의 값이 다른 변수의 동작을 설명할 수 있는지 확인하는 등 변수 간의 관계를 탐색하라는 메시지가 표시되는 경우가 많습니다. 이에 대해서는 곧 설명하겠습니다.

#### Unusual values

이상값은 패턴에 맞지 않는 데이터와 같이 비정상적인 관측값을 말합니다. 이상값은 데이터 입력 오류일 때도 있고, 데이터 수집에서 우연히 관찰된 극단의 값일 때도 있으며, 중요한 새로운 발견을 암시하는 것일 때도 있습니다. 데이터가 많으면 히스토그램에서 이상값을 확인하기 어려운 경우가 있습니다. 예를 들어 다이아몬드 데이터 집합에서 `y` 변수의 분포를 살펴봅시다. 이상값의 유일한 증거는 `X`축의 한계가 비정상적으로 넓다는 것입니다.

```{r}
ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5)
```

일반적인 항목은 관찰 값이 많고, 관찰 값이 작은 항목은 희소합니다. 비정상적인 값을 쉽게 보려면 `coord_cartesian()`을 사용하여 `y`축의 작은 값으로 확대해야 합니다.

```{r}
ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```

coord_cartesian()에는 x축을 조정하는 xlim()도 있습니다. ggplot2에는 약간 다르게 작동하는 xlim() 및 ylim() 함수도 있는데, 이들은 한계 밖의 데이터를 버립니다. 이를 통해 세 가지 특이한 값이 있음을 알 수 있습니다: 0, ~30, ~60입니다. dplyr로 이를 추출합니다.

```{r}
unusual <- diamonds |> 
  filter(y < 3 | y > 20) |> 
  select(price, x, y, z) |>
  arrange(y)
unusual
#> # A tibble: 9 × 4
#>   price     x     y     z
#>   <int> <dbl> <dbl> <dbl>
#> 1  5139  0      0    0   
#> 2  6381  0      0    0   
#> 3 12800  0      0    0   
#> 4 15686  0      0    0   
#> 5 18034  0      0    0   
#> 6  2130  0      0    0   
#> 7  2130  0      0    0   
#> 8  2075  5.15  31.8  5.12
#> 9 12210  8.09  58.9  8.06
```

`y` 변수는 이러한 다이아몬드의 세 가지 치수 중 하나를 `mm` 단위로 측정합니다. 다이아몬드의 너비가 `0 mm`일 수 없다는 것을 알고 있으므로 이 값은 틀린 값이어야 합니다. EDA를 수행하면서 `0`으로 코딩된 누락된 데이터를 발견했는데, 이는 단순히 `NA`를 검색했다면 결코 발견하지 못했을 것입니다. 

앞으로는 잘못된 계산을 방지하기 위해 이러한 값을 다시 NA로 변경할 수 있습니다. `32mm`와 59mm`의 측정값이 믿을 수 없다고 의심할 수도 있습니다. 이 다이아몬드는 길이에 비해서 금액이 적절하지 않기 때문입니다. 결과에 미치는 영향이 미미하고 이상값이 존재하는 이유를 파악할 수 없는 경우에는 이상값을 생략하고 다음 단계로 넘어가는 것이 합리적입니다. 그러나 결과에 상당한 영향을 미치는 경우라면 정당한 이유 없이 삭제해서는 안 됩니다. 데이터 입력 오류 등의 원인을 파악하고 글에서 해당 항목을 삭제했음을 밝혀야 합니다.

### 연습문제 10.3.3

#### 1

```{r}
summary(select(diamonds, x, y, z))
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = x), binwidth = 0.01)
```

```{r]}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = y), binwidth = 0.01)
```

```{r}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = z), binwidth = 0.01)
```

#### 2

```{r}
ggplot(filter(diamonds, price < 2500), aes(x = price)) +
  geom_histogram(binwidth = 10, center = 0)
```

```{r}
ggplot(filter(diamonds), aes(x = price)) +
  geom_histogram(binwidth = 100, center = 0)
```

```{r}
diamonds %>%
  mutate(ending = price %% 10) %>%
  ggplot(aes(x = ending)) +
  geom_histogram(binwidth = 1, center = 0)
```

```{r}
diamonds %>%
  mutate(ending = price %% 100) %>%
  ggplot(aes(x = ending)) +
  geom_histogram(binwidth = 1)
```

```{r}
diamonds %>%
  mutate(ending = price %% 1000) %>%
  filter(ending >= 500, ending <= 800) %>%
  ggplot(aes(x = ending)) +
  geom_histogram(binwidth = 1)
```

#### 3

```{r}
diamonds %>%
  filter(carat >= 0.99, carat <= 1) %>%
  count(carat)
```

```{r}
diamonds %>%
  filter(carat >= 0.9, carat <= 1.1) %>%
  count(carat) %>%
  print(n = Inf)
```

#### 4

```{r}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = price)) +
  coord_cartesian(xlim = c(100, 5000), ylim = c(0, 3000))
```

```{r}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = price)) +
  xlim(100, 5000) +
  ylim(0, 3000)
```

### Unusual values

데이터 집합에서 비정상적인 값을 발견하고 나머지 분석으로 넘어가고 싶은 경우, 두 가지 옵션이 있습니다.

1. 이상한 값이 있는 전체 행을 삭제합니다.

```{r}
#| eval: false
diamonds2 <- diamonds |> 
  filter(between(y, 3, 20))
```

하나의 유효하지 않은 값이 있다고 해서 해당 관찰에 대한 다른 모든 값도 유효하지 않다는 의미는 아니므로 이 옵션을 권장하지 않습니다. 또한 품질이 낮은 데이터가 있는 경우 모든 변수에 이 접근 방식을 적용했을 때 남은 데이터가 없을 수도 있습니다!

2. 대신 비정상적인 값을 누락된 값으로 대체하는 것이 좋습니다. 

```{r}
diamonds2 <- diamonds |> 
  mutate(y = if_else(y < 3 | y > 20, NA, y))
```

누락된 값을 어디에 그려야 하는지 명확하지 않으므로 ggplot2는 누락된 값을 플롯에 포함하지 않지만, 누락된 값이 제거되었음을 경고합니다.

```{r}
ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point()
```

이 경고를 표시하지 않으려면 `na.rm = TRUE`를 설정합니다.

```{r}
#| eval: false

ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point(na.rm = TRUE)
```

새 변수를 만들고 `is.na()`를 사용하여 `dep_time`이 누락되었는지 확인하면 이 작업을 수행할 수 있습니다.

```{r}
nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time)) + 
  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)
```

하지만 취소된 항공편보다 취소되지 않은 항공편이 훨씬 더 많기 때문에 이 계획은 좋지 않습니다.

### 연습문제 10.4.1

#### 1

```{r}
diamonds2 <- diamonds %>%
  mutate(y = ifelse(y < 3 | y > 20, NA, y))

ggplot(diamonds2, aes(x = y)) +
  geom_histogram()
```

```{r}
diamonds %>%
  mutate(cut = if_else(runif(n()) < 0.1, NA_character_, as.character(cut))) %>%
  ggplot() +
  geom_bar(mapping = aes(x = cut))
```

#### 2

```{r}
mean(c(0, 1, 2, NA), na.rm = TRUE)
sum(c(0, 1, 2, NA), na.rm = TRUE)
```

### Covariation

#### A categorical and a numerical variable

```{r}
ggplot(diamonds, aes(x = price)) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```

ggplot2는 데이터에서 정렬된 요소 변수로 정의되기 때문에 `cut`에 정렬된 색 눈금을 사용합니다. 전체 개수에 의해 결정되는 높이가 'cut'에 따라 너무 많이 달라져 분포의 모양 차이를 확인하기 어렵기 때문에 `geom_freqpoly()`의 기본 모양은 여기서 그다지 유용하지 않습니다.

비교를 쉽게 하기 위해 Y축에 표시되는 내용을 바꿔야 합니다. 개수를 표시하는 대신 각 주파수 다각형 아래의 면적이 1이 되도록 표준화된 개수인 **밀도**를 표시합니다.

```{r}
ggplot(diamonds, aes(x = price, y = after_stat(density))) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```

밀도를 'y'에 매핑하고 있지만 '다이아몬드' 데이터 집합에는 '밀도'가 변수가 아니므로 먼저 밀도를 계산해야 합니다. 이를 위해 `after_stat()` 함수를 사용합니다. 이 플롯에는 다소 놀라운 점이 있는데, 가장 품질이 낮은 페어 다이아몬드의 평균 가격이 가장 높은 것으로 나타났습니다! 하지만 주파수 다각형이 해석하기 조금 어렵기 때문일 수도 있습니다. 이 플롯에는 많은 일이 일어나고 있습니다.

이 관계를 탐색하는 데 시각적으로 더 간단한 플롯은 나란히 배치된 박스 플롯을 사용하는 것입니다.

```{r}
ggplot(diamonds, aes(x = cut, y = price)) +
  geom_boxplot()
```

분포에 대한 정보는 훨씬 적지만, 박스 플롯이 훨씬 더 간결해져 더 쉽게 비교할 수 있고 한 플롯에 더 많은 것을 담을 수 있습니다. 이는 일반적으로 더 좋은 품질의 다이아몬드가 더 저렴하다는 반직관적인 결과를 뒷받침합니다! 연습 문제에서는 그 이유를 알아내야 합니다.

`cut`은 순서가 있는 요소입니다. 즉, 보통은 좋음보다 나쁘고, 좋음은 매우 좋음보다 나쁘다는 식입니다. 많은 범주형 변수는 이러한 내재적 순서가 없으므로 더 많은 정보를 표시하기 위해 순서를 바꾸고 싶을 수 있습니다. 이를 위한 한 가지 방법은 `fct_reorder()`를 사용하는 것입니다. 예를 들어, `mpg` 데이터 집합의 `class` 변수를 살펴봅시다. 고속도로 주행 거리가 등급에 따라 어떻게 달라지는지 알고 싶을 수 있습니다.

```{r}
ggplot(mpg, aes(x = class, y = hwy)) +
  geom_boxplot()
```

추세를 더 쉽게 볼 수 있도록 'class'의 중앙값을 기준으로 'hwy'의 순서를 바꿀 수 있습니다.

```{r}
ggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +
  geom_boxplot()
```

변수 이름이 긴 경우 `geom_boxplot()`을 90°로 뒤집으면 더 잘 작동합니다. X와 Y의 미적 매핑을 교환하면 됩니다.

```{r}
ggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +
  geom_boxplot()
```

#### 연습문제 10.5.1.1

1. None

2. None

3. None

4. None

5. None

6. None

#### Two categorical variables

범주형 변수 간의 공변량을 시각화하려면 이러한 범주형 변수의 각 수준 조합에 대한 관찰 횟수를 계산해야 합니다. 이를 수행하는 한 가지 방법은 내장된 `geom_count()`를 사용하는 것입니다:

```{r}
ggplot(diamonds, aes(x = cut, y = color)) +
  geom_count()
```

플롯에서 각 원의 크기는 각 값 조합에서 발생한 관찰 횟수를 표시합니다. 공변량은 특정 x 값과 특정 y 값 사이의 강한 상관관계로 나타납니다. 이러한 변수 간의 관계를 탐색하는 또 다른 접근 방식은 dplyr로 개수를 계산하는 것입니다.

```{r}
diamonds |> 
  count(color, cut)
```

그런 다음 `geom_tile()`과 채우기 미학을 사용하여 시각화합니다.

```{r}
diamonds |> 
  count(color, cut) |>  
  ggplot(aes(x = color, y = cut)) +
  geom_tile(aes(fill = n))
```

범주형 변수의 순서가 지정되지 않은 경우, 흥미로운 패턴을 보다 명확하게 드러내기 위해 직렬화 패키지를 사용하여 행과 열의 순서를 동시에 재정렬할 수 있습니다. 더 큰 플롯의 경우 대화형 플롯을 만드는 히트맵리 패키지를 사용해 볼 수 있습니다.

#### 연습문제 10.5.2.1

1.  None

2.  None

3.  None

#### Two numerical variables

두 숫자 변수 간의 공분산을 시각화하는 한 가지 좋은 방법은 `geom_point()`로 산점도를 그리는 것입니다. 점의 패턴으로 공분산을 볼 수 있습니다. 예를 들어 다이아몬드의 캐럿 크기와 가격 간에 양의 관계가 있음을 알 수 있습니다. 캐럿이 많은 다이아몬드는 가격이 더 높습니다. 이 관계는 기하급수적입니다.

```{r}
ggplot(smaller, aes(x = carat, y = price)) +
  geom_point()
```

분산형 차트는 데이터 집합의 크기가 커지면 점들이 겹치기 시작하고 균일한 검은색 영역으로 쌓이기 시작하여 2차원 공간에서 데이터 밀도의 차이를 판단하기 어려울 뿐만 아니라 추세를 파악하기 어렵게 되므로 그 유용성이 떨어집니다. 이 문제를 해결할 수 있는 한 가지 방법은 '알파' 미학을 사용하여 투명도를 추가하는 것입니다.

```{r}
ggplot(smaller, aes(x = carat, y = price)) + 
  geom_point(alpha = 1 / 100)
```

```{r}
ggplot(smaller, aes(x = carat, y = price)) +
  geom_bin2d()

# install.packages("hexbin")
ggplot(smaller, aes(x = carat, y = price)) +
  geom_hex()
```

```{r}
ggplot(smaller, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_width(carat, 0.1)))
```


#### 연습문제 10.5.3.1

1.  None

2.  None

3.  None

4.  None

5.  None

```{r}
diamonds |> 
  filter(x >= 4) |> 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```

6.  

```{r}
ggplot(smaller, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_number(carat, 20)))
```

### Patterns and models

```{r}
library(tidymodels)

diamonds <- diamonds |>
  mutate(
    log_price = log(price),
    log_carat = log(carat)
  )

diamonds_fit <- linear_reg() |>
  fit(log_price ~ log_carat, data = diamonds)

diamonds_aug <- augment(diamonds_fit, new_data = diamonds) |>
  mutate(.resid = exp(.resid))

ggplot(diamonds_aug, aes(x = carat, y = .resid)) + 
  geom_point()
```

```{r}
ggplot(diamonds_aug, aes(x = cut, y = .resid)) + 
  geom_boxplot()
```
